{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore elements of galaxy survey design using the heirarchical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we'll be exploring some elements of what is important and effective when designing surveys, using full arbitrary mass measurement uncertainties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from mrpy.fit_perobj import fit_perobj_stan\n",
    "from mrpy import TGGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our main question will be this:\n",
    "\n",
    "> Supposing we keep the number of galaxies surveyed fixed at *N*, is it better for cosntraints on the MRP if these\n",
    "> galaxies are deep (i.e. low truncation mass with small volume) or shallow (i.e. high truncation mass with large volume)?\n",
    "\n",
    "The answer to the question is *a prior* not obvious. While making the truncation mass lower will increase the range we can access information in our fit, the higher-mass objects are inherently less uncertain in their measurement, and could control the all-important pivot region.\n",
    "\n",
    "Our initial attack at the problem will be to generate a series of samples with differing truncation masses, but with the same number of galaxies, and fit each sample using our heirarchical Stan model. Importantly, we must use a relation for the uncertainty in the masses, as a function of mass. This will be gotten from data...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by creating intrinsic samples for each selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The basic parameters of our runs\n",
    "N = 50000\n",
    "mmins = np.linspace(10.0,13.5,7)\n",
    "\n",
    "# MRP parameters\n",
    "logHs = 14.5\n",
    "alpha = -1.9\n",
    "beta  = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intrinsic_masses = np.zeros((N,len(mmins)))\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "for i,mmin in enumerate(mmins):\n",
    "    intrinsic_masses[:,i] = np.log10(TGGD(10**logHs,alpha,beta,10**mmin).rvs(N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add uncertainty to each sample, based on our uncertainty model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding uncertainty...\n",
    "#measured_masses = measure(intrinsic_masses,seed=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Stan Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First specify some general parameters to use in the estimation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warmup = 500\n",
    "iters = 1500\n",
    "chains = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define a function that will fit a given sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_fit(masses,mmin):\n",
    "    init = [{\"logHs\":logHs,\"alpha\":alpha,\"beta\":beta,\"log_mtrue\":masses,\"log_mmin\":masses.min()-0.01}]*chains\n",
    "    \n",
    "    # Run the sampling\n",
    "    fit_err = fit_perobj_stan(10**masses,sd,warmup=warmup,iter=iters,hs_bounds=(logHs-2,logHs+2),\n",
    "                              alpha_bounds=(-1.99,-1.5),beta_bounds=(beta-0.3,beta+0.3),\n",
    "                              mmin_bounds=(11,13),n_jobs=chains,chains=chains,init=init,\n",
    "                              pars=['logHs',\"alpha\",\"beta\",'log_mmin'],model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fit each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i,mmin in enumerate(mmins):\n",
    "#    result = run_fit()"
   ]
  }
 ],
 "metadata": {
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
